{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"more_pets_tflite.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"cSzB3KIIMqmQ","colab_type":"text"},"source":["# Image Classification: More Pets\n","\n","\n","This notebook trains a model using TensorFlow to classify an image as a rabbit, mouse, hamster, fish, lizard, or snake. \n","\n","Below we do the following:\n","\n","1. Setup training environment.\n","2. Load images of rabbits, mic, hamsters, fish, lizards, and snakes.\n","3. Train an image classifier model using the TensorFlow library, leveraging transfer learning and MobileNetV2.\n","4. Convert the model from TensorFlow to TF-Lite. \n","\n","This workflow is based on two examples provided in the TensorFlow-Lite documentation: \n","\n","* https://www.tensorflow.org/tutorials/images/transfer_learning\n","* https://github.com/tensorflow/examples/blob/master/community/en/flowers_tf_lite.ipynb\n","\n","It is also important to note that this Notebook is using a GPU run-time to speed up the training process. Without a GPU, model training will take significantly longer! "]},{"cell_type":"code","metadata":{"id":"wJJXitKVOpAX","colab_type":"code","colab":{}},"source":["# First, we need to import the necessary libraries.\n","!pip install tensorflow-gpu==2.0.0-beta1 \n","\n","import tensorflow as tf\n","\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NfrWQSI7QV7S","colab_type":"code","colab":{}},"source":["# Let's validate our version of TensorFlow\n","tf.__version__"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gP_0kb4eP8je","colab_type":"text"},"source":["## Data Preparation\n","\n","The training data for this example are hundreds of images of various animals, pulled from the [Open Images Dataset v4](https://storage.googleapis.com/openimages/web/download_v4.html).\n","\n","The code below does the following: \n","\n","* Downloads the data from a public S3 bucket provided by Skafos. \n","* Validates that the expected categories are present\n","* Creates the necessary `ImageDataGenerator` required by TensorFlow and then splits the data into training and validation sets\n","* Saves the category labels in a file `labels.txt` for later download. "]},{"cell_type":"code","metadata":{"id":"dEeXaNQSv-OF","colab_type":"code","colab":{}},"source":["# Specify the location of the data set\n","_URL = \"https://s3.amazonaws.com/skafos.example.data/ImageClassifier/MorePets.tar.gz\"\n","\n","# Download the file and extract the images \n","zip_file = tf.keras.utils.get_file(origin=_URL, \n","                                   fname=\"MorePets.tar.gz\", \n","                                   extract=True)\n","\n","# Specify the base directory for the data set\n","base_dir = os.path.join(os.path.dirname(zip_file), 'MorePets')\n","\n","# Validate that the categories present are what you'd expect\n","os.listdir(base_dir)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aH8XWyqkxW-u","colab_type":"code","colab":{}},"source":["# Set the image side and batch size. Becasue we will be using MobileNetV2, we will set the image size to 224x224. \n","# For more information, see: https://keras.io/applications/#mobilenetv2\n","IMAGE_SIZE = 224  \n","BATCH_SIZE = 64\n","NUMBER_OF_LABELS = len(os.listdir(base_dir)) \n","\n","# Create data generator with appropriate scaling and train/validation split\n","datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n","    rescale=1./255, \n","    validation_split=0.2)\n","\n","# Create training dataset\n","train_generator = datagen.flow_from_directory(\n","    base_dir,\n","    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n","    batch_size=BATCH_SIZE, \n","    subset='training')\n","\n","# Create validation dataset\n","val_generator = datagen.flow_from_directory(\n","    base_dir,\n","    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n","    batch_size=BATCH_SIZE, \n","    subset='validation')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2532mQ1h43Jm","colab_type":"code","colab":{}},"source":["# Create labels.txt file, which we will need to export and save for use in our app\n","print (train_generator.class_indices)\n","\n","labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n","\n","with open('labels.txt', 'w') as f:\n","  f.write(labels)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rKg2lx6r5Fnz","colab_type":"text"},"source":["## Model Training\n","\n","Transfer learning leverages pre-existing \"base models\" to make your model training faster. In this example, we will use the MobileNetV2 model as our base model. This model was developed at Google, and pre-trained on the ImageNet dataset, a large dataset of 1.4M images and 1000 classes of web images.\n","\n","To construct a model leveraging transfer learning in TensorFlow, we will take the following steps: \n","\n","* Do feature extraction by freezing the convolutional base model and adding classification layers on top. \n","* Compile + fit the model\n","* Fine tune the model by unfreezing the base model, and allowing fine-tuning of the base model weights for additional layers of the network. \n","\n","For more information about transfer learning in TensorFlow, [please review the TensorFlow documentation](https://www.tensorflow.org/tutorials/images/transfer_learning). Thie documentation will provide more context and information about how transfer learning works in TensorFlow. "]},{"cell_type":"code","metadata":{"id":"1HSEpY087klE","colab_type":"code","colab":{}},"source":["# Set the image shape based on the image size specified above. \n","IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3) \n","\n","# Create the base model from the pre-trained model MobileNet V2\n","base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n","                                              include_top=False, \n","                                              weights='imagenet')\n","\n","# Freeze the base_model\n","base_model.trainable = False\n","\n","# Add classification layers on top of the base model\n","model = tf.keras.Sequential([\n","  base_model,\n","  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n","  tf.keras.layers.Dropout(0.2),\n","  tf.keras.layers.GlobalAveragePooling2D(),\n","  tf.keras.layers.Dense(NUMBER_OF_LABELS, activation='softmax')\n","])\n","\n","# Compile the model. The optimal loss function depends on the type of model you want to build. \n","# This article provides a thorough summary: https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n","model.compile(optimizer=tf.keras.optimizers.Adam(), \n","              loss='categorical_crossentropy', \n","              metrics=['accuracy'])\n","\n","# To get a summary of the model, uncomment the line below\n","#model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZKlqEKHO83c7","colab_type":"code","colab":{}},"source":["# Train the model. This will likely take a few minutes. Increasing the number of epochs will increase the model training time, and can be tuned for optimal accuracy.  \n","history = model.fit(train_generator, \n","                    epochs=10, \n","                    validation_data=val_generator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rt5InnF39QG5","colab_type":"code","colab":{}},"source":["# Begin the fine-tuning process by allowing training of the base_model\n","base_model.trainable = True\n","\n","# This print statement will tell us the number of layers in the base model\n","print(\"Number of layers in the base model: \", len(base_model.layers))\n","\n","# Fine tune from this layer onwards. This number must be less than len(base_model.layers)). In this example, we've chosen 100. \n","fine_tune_at = 100\n","\n","# Freeze all the layers before the `fine_tune_at` layer\n","for layer in base_model.layers[:fine_tune_at]:\n","  layer.trainable =  False\n","  \n","# Compile the model. Note that we have chosen a different optimizer from previously\n","model.compile(optimizer = tf.keras.optimizers.Adam(1e-5),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VDDU7QX4_56y","colab_type":"code","colab":{}},"source":["# Train the model, fine tuning this time. \n","history_fine = model.fit(train_generator, \n","                         epochs=20,\n","                         validation_data=val_generator)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"quyu79HyAO3X","colab_type":"text"},"source":["## Model Validation\n","\n","Using the matplot lib library, we can plot our model accuracy and loss. \n","\n","We can also use the model to do inference on a new image as another way to test it. "]},{"cell_type":"code","metadata":{"id":"tSRecGO3AwhS","colab_type":"code","colab":{}},"source":["# Plotting accuracy and loss\n","acc = history_fine.history['accuracy']\n","val_acc = history_fine.history['val_accuracy']\n","\n","loss = history_fine.history['loss']\n","val_loss = history_fine.history['val_loss']\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(2, 1, 1)\n","plt.plot(acc, label='Training Accuracy')\n","plt.plot(val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.ylabel('Accuracy')\n","plt.ylim([min(plt.ylim()),1])\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(2, 1, 2)\n","plt.plot(loss, label='Training Loss')\n","plt.plot(val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.ylabel('Cross Entropy')\n","plt.ylim([0,1.0])\n","plt.title('Training and Validation Loss')\n","plt.xlabel('epoch')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OaHhzDglA3zP","colab_type":"code","colab":{}},"source":["# Let's use this model to make a prediction on a new image to test it\n","import numpy as np\n","import PIL.Image as Image\n","\n","# The image URL below is from the Google Open Images Dataset\n","test_image_URL = 'https://c1.staticflickr.com/4/3581/3407856156_415b3fd8ee_o.jpg'\n","test_image = tf.keras.utils.get_file('image.jpg', test_image_URL) \n","test_image = Image.open(test_image)\n","\n","# Keep aspect ratio when resizing \n","#wpercent = (IMAGE_SIZE / float(test_image.size[0]))\n","#hsize = int((float(test_image.size[1]) * float(wpercent)))\n","test_image = test_image.resize((IMAGE_SIZE, IMAGE_SIZE), Image.ANTIALIAS)\n","\n","# Let's view the image to see what it is\n","test_image"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2OUEIZqoYEt-","colab_type":"code","colab":{}},"source":["# Now we need to scale the model before predicting and add a batch size via the tf.expand_dims command\n","test_image = np.array(test_image)/255.0\n","test_image.shape = tf.shape(tf.expand_dims(test_image, 0)) \n","\n","# Use the model object to predict what this image is\n","prediction = model.predict(test_image)\n","\n","# Get the predicted class label as the max value from the array of predictions\n","predicted_class = np.argmax(prediction[0], axis=-1)\n","\n","# Get the corresponding label from train_generator.class_indices\n","predicted_class = np.argmax(prediction[0], axis=-1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6MEMsZrGB4F0","colab_type":"text"},"source":["## Convert your model to TensorFlow Lite and Export\n","\n","As a final step to optimize your model for use on mobile devices, we need to convert our model from TensorFlow to TensorFlow-Lite. After conversion, we will download it for inclusion in our mobile app. \n","\n","More information about converting from TensorFlow to TensorFlow Lite is available here: https://www.tensorflow.org/lite/r2/convert/python_api"]},{"cell_type":"code","metadata":{"id":"WW9F5bJ2CeXY","colab_type":"code","colab":{}},"source":["# Convert our model to TFLite\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","\n","with open('model.tflite', 'wb') as f:\n","  f.write(tflite_model)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cfbBZ46zDj8j","colab_type":"code","colab":{}},"source":["# Download the model for inclusion in a mobile app. \n","# Soon, we will be able to use the Skafos SDK to deliver the model directly to Skafos \n","\n","from google.colab import files\n","\n","files.download('model.tflite')\n","files.download('labels.txt')"],"execution_count":0,"outputs":[]}]}