{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "phrase_generator_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2gCxAcKvrNx",
        "colab_type": "text"
      },
      "source": [
        "# **Phrase Generator Model**\n",
        "\n",
        "This notebook trains a model using Keras (and TensorFlow Backend) to finish your phrase in the style of author/poet William Shakespeare. \n",
        "\n",
        "Below we do the following:\n",
        "1. Setup training environment \n",
        "2. Load and clean the Shakespeare test samples.\n",
        "3. Train a word-level, neural network language model.\n",
        "4. Convert the model to CoreML format.\n",
        "5. Deliver the model to an app using Skafos\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pawWdk24wGQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First, let's install the tools and dependencies we need. \n",
        "!pip install keras skafos coremltools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvB3QO1AcIMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import tools and libraries\n",
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "import urllib\n",
        "\n",
        "import skafos\n",
        "from skafos import models\n",
        "import numpy as np\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E58ZeBtmcNQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check the skafos version\n",
        "skafos.get_version()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWJMy3SABYlk",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation\n",
        "The training data for this example are samples of text from some pieces authored by William Shakespeare. \n",
        "\n",
        "The code below does the following:\n",
        "\n",
        "- Downloads the data from a public S3 bucket provided by Skafos.\n",
        "- Defines some helper functions to parse the text.\n",
        "- Tokenizes the text.\n",
        "- Prepares the training data, building input sequences for the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhPJ14mg0urj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify the data set download url\n",
        "data_path = \"Shakespeare.zip\"\n",
        "data_url = \"https://s3.amazonaws.com/skafos.example.data/PhraseGenModel/{}\".format(data_path)\n",
        "\n",
        "# Download the dataset\n",
        "retrieve = urllib.request.urlretrieve(data_url, data_path)\n",
        "\n",
        "# Unzip\n",
        "zip_ref = zipfile.ZipFile(data_path, 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niP8FsLt0unC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper functions\n",
        "# Remove stage direction and comments\n",
        "def remove_stage_dir(text):\n",
        "    text = re.sub(\"[\\<].*?[\\>]\", \"\", text)\n",
        "    text = re.sub(\"\\\\s+\", \" \", text)\n",
        "    return text\n",
        "  \n",
        "# Remove the word \"SPEECH\" adn the number following after that in the corpus\n",
        "def remove_SPEECH(text):\n",
        "    text = re.sub(\"SPEECH \\d+\", \"\", text)\n",
        "    text = re.sub(\"\\\\s+\", \" \", text)\n",
        "    return text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aARnGVT0uiu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in Shakespeare files\n",
        "\n",
        "in_sentences = []\n",
        "\n",
        "for filename in os.listdir():\n",
        "    if filename.endswith(\".txt\"):\n",
        "        text = ''.join(open(filename, encoding = \"utf-8-sig\", mode=\"r\").readlines())\n",
        "        # Chop up into sentences\n",
        "        split_text = re.split(r' *[\\.\\?!][\\'\"\\)\\]]* *', remove_stage_dir(text))\n",
        "        for chunk in split_text:\n",
        "            in_sentences.append(chunk.strip())\n",
        "\n",
        "print(in_sentences[0:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRXLkeWf0uei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Some constants\n",
        "# Length of extracted text sample\n",
        "maxlen = 10\n",
        "# Stride of sampling\n",
        "step = 2\n",
        "# This holds our samples sequences\n",
        "sentences = []\n",
        "# This holds the next word (as training label)\n",
        "next_word = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVzH0tjg21kG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare the Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(list(in_sentences))\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(list(in_sentences))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Umm2PtQH6mM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(f'{vocab_size} total unique words in our training data corpus', flush=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6u1AhLi4bvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stick the encoded words back together as a long sequence\n",
        "token_word = []\n",
        "for line in range (0,len(in_sentences)):\n",
        "    that_sentences = list_tokenized_train[line]\n",
        "    for i in range(0,len(that_sentences)):\n",
        "        token_word.append(that_sentences[i])\n",
        "\n",
        "# Sample from the sequence\n",
        "for i in range(0, len(token_word) - maxlen, step):\n",
        "    sentences.append(token_word[i: i + maxlen])\n",
        "    next_word.append(token_word[i + maxlen])\n",
        "print('Number of sentences:', len(sentences))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sSO5kWe79qz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare the training data sequences\n",
        "x = np.asarray(sentences)\n",
        "y = to_categorical(next_word, num_classes=vocab_size)\n",
        "seq_length = x.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq4r6tXHbFtS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Do some garbage collection\n",
        "del(sentences, in_sentences, next_word, token_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz5oH9GvdFJ4",
        "colab_type": "text"
      },
      "source": [
        "## Model Training\n",
        "The phrase generation model takes sequences of tokenized text as input and tries to predict the most likely next word from the vocabulary. You can create phrases by recursively feeding previous predictions, adding a single word at a time to a phrase.. almost like a \"digital Shakespeare\". The Keras model uses three different layer types in the neural network: Embedding, LSTM, and Dense. Links to relevant documentation are provided in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-D8nenRDpAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=256, input_length=seq_length))  # Docs: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
        "model.add(LSTM(units=256))                                                           # Docs: https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM\n",
        "model.add(Dense(vocab_size, activation='softmax'))                                   # Docs: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\n",
        "print(model.summary(), flush=True)\n",
        "\n",
        "# Compile the model\n",
        "# Since our predictions are one-hot encoded, use `categorical_crossentropy` as the loss\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) # keep track of accuracy along the way"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPkiaP0_ELcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model for a few epochs\n",
        "model.fit(x, y, batch_size=256, epochs=15)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T02r9CDLHvDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pickup training from where you left off last with the following\n",
        "# Using an initial_epoch of 15 and epochs of 20, the model will begin at epoch 16 and train up until it reaches 20 (from where you last left off)\n",
        "model.fit(x, y, batch_size=256, initial_epoch=15, epochs=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GPwb2NECaGy",
        "colab_type": "text"
      },
      "source": [
        "## Model Validation\n",
        "Below we reverse and export the tokenizer so we can lookup a word based on it's index. Then we test out the newly trained model with some sample text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7mE2NVSIJbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "# Invert the tokenizer map so we can lookup a word by it's index\n",
        "index_word_lookup = dict(map(reversed, tokenizer.word_index.items()))\n",
        "index_word_lookup_file = 'index_word_lookup.json'\n",
        "\n",
        "# Save it to a json object\n",
        "with open(index_word_lookup_file, 'w') as fp:\n",
        "    json.dump(index_word_lookup, fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L24IScxvrOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Function to generate new text based on the input\n",
        "def generate_text(seed_text, next_words, max_sequence_len, model):\n",
        "    for j in range(next_words):\n",
        "        token_list = pad_sequences(\n",
        "            sequences=tokenizer.texts_to_sequences([seed_text]),\n",
        "            maxlen=max_sequence_len,\n",
        "            padding='pre'\n",
        "        )\n",
        "        predicted = model.predict_classes(token_list, verbose=0)\n",
        "        # Generate the output word\n",
        "        seed_text += \" \" + index_word_lookup[predicted[0]]\n",
        "    return seed_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_G4-0ltvrOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test out the language model by passing in some seed text and the number of words\n",
        "generate_text(\"You shall go see\", 3, maxlen, model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7i0wdvmvrOT",
        "colab_type": "text"
      },
      "source": [
        "## Deliver your model to an iOS App with Skafos\n",
        "\n",
        "As a final step to optimize your model for use on mobile devices, we need to convert our model from a Keras object to CoreML format. After conversion, we will use the [Skafos SDK](https://sdk.skafos.ai) to upload it to Skafos!\n",
        "\n",
        "To execute the following steps, you will need to do the following:\n",
        "\n",
        "- [Sign-up for a Skafos account](https://dashboard.skafos.ai/sign-up) if you haven't already.\n",
        "- Navigate to the [account settings page on Skafos](https://dashboard.skafos.ai/settings/account) to get an API token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3uF122IvrOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import coremltools\n",
        "\n",
        "# Convert the language model to Core ML format\n",
        "model_name = \"PhraseGenModel\"\n",
        "coreml_model_name = model_name + \".mlmodel\"\n",
        "coreml_model = coremltools.converters.keras.convert(\n",
        "    model,\n",
        "    input_names=['tokenizedInputSeq'],\n",
        "    output_names=['tokenProbs']\n",
        ")\n",
        "\n",
        "# Add description information (if you want) and save the file\n",
        "coreml_model.short_description = 'Predicts the most likely next word given a string of text'\n",
        "coreml_model.input_description['tokenizedInputSeq'] = 'An array of tokenized text'\n",
        "coreml_model.output_description['tokenProbs'] = 'An array of token probabilities across the entire vocabulary'\n",
        "coreml_model.save(coreml_model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2fDiqFhvrOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Skafos SDK Upload Model Version \n",
        "\n",
        "# Set your API Token first for repeated use\n",
        "os.environ[\"SKAFOS_API_TOKEN\"] = \"<YOUR-SKAFOS-API-TOKEN>\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdjT2HyHNaCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get a summary of your existing apps and models on Skafos, so you can determine where to deliver this model.\n",
        "res = skafos.summary()\n",
        "print(res)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVi31i9gNX8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You can retrieve this info with skafos.summary()\n",
        "org_name = \"<YOUR-SKAFOS-ORG-NAME>\"    # Example: \"mike-gmail-com-467h2\"\n",
        "app_name = \"<YOUR-SKAFOS-APP-NAME>\"    # Example: \"PhraseGenerator\"\n",
        "model_name = \"<YOUR-SKAFOS-MODEL-NAME>\"       # Example: \"PhraseGenModel\"\n",
        "\n",
        "# Upload model version to Skafos\n",
        "model_upload_result = models.upload_version(\n",
        "    files = [coreml_model_name, index_word_lookup_file],\n",
        "    description = \"Shakespeare model\",\n",
        "    org_name = org_name,\n",
        "    app_name = app_name,\n",
        "    model_name = model_name\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}